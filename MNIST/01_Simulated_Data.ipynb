{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/autoencoder-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train autoencoder for classification with no compression in the bottleneck layer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# evaluate logistic regression on encoded input\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# baseline in performance with logistic regression model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "# number of input columns\n",
    "n_inputs = X.shape[1]\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Check with simple logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# fit model on training set\n",
    "model.fit(X_train, y_train)\n",
    "# make prediction on test set\n",
    "yhat = model.predict(X_test)\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 Create Auto Encoder Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "# n_bottleneck = n_inputs\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03a Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Epoch 1/200\n",
      "42/42 - 2s - loss: 0.2258 - val_loss: 0.1579\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.0335 - val_loss: 0.0924\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.0212 - val_loss: 0.0440\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.0174 - val_loss: 0.0274\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.0157 - val_loss: 0.0190\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.0081 - val_loss: 0.0038\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.0082 - val_loss: 0.0045\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 8.5442e-04\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0029 - val_loss: 8.9025e-04\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0027 - val_loss: 9.1794e-04\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0030 - val_loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03b Test Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/gfxhome/asislam25/.conda/envs/venv_vasic_gpu/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "# calculate classification accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Process data and add label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04a Add -1 to train, at the left end of the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 100)\n",
      "[0.28409835 0.31924041 0.34551485 0.66209953 0.66954696 0.68804867\n",
      " 0.59032621 0.46009324 0.58172961 0.43673349]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 101)\n",
      "[ 0.31924041  0.34551485  0.66209953  0.66954696  0.68804867  0.59032621\n",
      "  0.46009324  0.58172961  0.43673349 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.ones((X_train.shape[0],X_train.shape[1]+1))\n",
    "b=-b\n",
    "print(b.shape)\n",
    "b[:,:-1] = X_train\n",
    "print(b[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31924041  0.34551485  0.66209953  0.66954696  0.68804867  0.59032621\n",
      "  0.46009324  0.58172961  0.43673349 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "X_train_left=b\n",
    "print(X_train_left[0][-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04b Add labels (y values) to train, at the right end of the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28409835 0.31924041 0.34551485 0.66209953 0.66954696 0.68804867\n",
      " 0.59032621 0.46009324 0.58172961 0.43673349]\n",
      "[0 1 0 0 1 1 0 1 0 1]\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "(670, 101)\n",
      "[0.31924041 0.34551485 0.66209953 0.66954696 0.68804867 0.59032621\n",
      " 0.46009324 0.58172961 0.43673349 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][-10:])\n",
    "y_train.shape\n",
    "print(y_train[:10])\n",
    "b = np.ones((X_train.shape[0],X_train.shape[1]+1))\n",
    "b[:,-1]=y_train\n",
    "print(b[:,-1][:10])\n",
    "print(b.shape)\n",
    "b[:,:-1] = X_train\n",
    "X_train_right=b\n",
    "print(X_train_right[0][-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04c Add -1 to test, at the left end of the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 100)\n",
      "[0.37016381 0.24216292 0.30287124 0.68046848 0.57707226 0.57707664\n",
      " 0.35729957 0.28796688 0.52172132 0.53536197]\n",
      "(330, 101)\n",
      "[ 0.24216292  0.30287124  0.68046848  0.57707226  0.57707664  0.35729957\n",
      "  0.28796688  0.52172132  0.53536197 -1.        ]\n",
      "[ 0.24216292  0.30287124  0.68046848  0.57707226  0.57707664  0.35729957\n",
      "  0.28796688  0.52172132  0.53536197 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test[0][-10:])\n",
    "b = np.ones((X_test.shape[0],X_test.shape[1]+1))\n",
    "b=-b\n",
    "print(b.shape)\n",
    "b[:,:-1] = X_test\n",
    "print(b[0][-10:])\n",
    "X_test_left=b\n",
    "print(X_test_left[0][-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04d Add label(y value) to test, at the right end of the auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37016381 0.24216292 0.30287124 0.68046848 0.57707226 0.57707664\n",
      " 0.35729957 0.28796688 0.52172132 0.53536197]\n",
      "[0 1 0 1 0 0 0 1 1 0]\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "(330, 101)\n",
      "[0.24216292 0.30287124 0.68046848 0.57707226 0.57707664 0.35729957\n",
      " 0.28796688 0.52172132 0.53536197 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0][-10:])\n",
    "y_test.shape\n",
    "print(y_test[:10])\n",
    "b = np.ones((X_test.shape[0],X_test.shape[1]+1))\n",
    "b[:,-1]=y_test\n",
    "print(b[:,-1][:10])\n",
    "print(b.shape)\n",
    "b[:,:-1] = X_test\n",
    "X_test_right=b\n",
    "print(X_test_right[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 101) (670, 101)\n",
      "(330, 101) (330, 101)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_left.shape,X_train_right.shape)\n",
    "print(X_test_left.shape,X_test_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train_left.shape[1]\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "# n_bottleneck = n_inputs\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Epoch 1/200\n",
      "42/42 - 1s - loss: 0.2276 - val_loss: 0.1773\n",
      "Epoch 2/200\n",
      "42/42 - 0s - loss: 0.0406 - val_loss: 0.1190\n",
      "Epoch 3/200\n",
      "42/42 - 0s - loss: 0.0265 - val_loss: 0.0644\n",
      "Epoch 4/200\n",
      "42/42 - 0s - loss: 0.0210 - val_loss: 0.0380\n",
      "Epoch 5/200\n",
      "42/42 - 0s - loss: 0.0183 - val_loss: 0.0235\n",
      "Epoch 6/200\n",
      "42/42 - 0s - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 7/200\n",
      "42/42 - 0s - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 8/200\n",
      "42/42 - 0s - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 9/200\n",
      "42/42 - 0s - loss: 0.0130 - val_loss: 0.0085\n",
      "Epoch 10/200\n",
      "42/42 - 0s - loss: 0.0128 - val_loss: 0.0075\n",
      "Epoch 11/200\n",
      "42/42 - 0s - loss: 0.0120 - val_loss: 0.0069\n",
      "Epoch 12/200\n",
      "42/42 - 0s - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 13/200\n",
      "42/42 - 0s - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 14/200\n",
      "42/42 - 0s - loss: 0.0105 - val_loss: 0.0059\n",
      "Epoch 15/200\n",
      "42/42 - 0s - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 16/200\n",
      "42/42 - 0s - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 17/200\n",
      "42/42 - 0s - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 18/200\n",
      "42/42 - 0s - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 19/200\n",
      "42/42 - 0s - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 20/200\n",
      "42/42 - 0s - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 21/200\n",
      "42/42 - 0s - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 22/200\n",
      "42/42 - 0s - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 23/200\n",
      "42/42 - 0s - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 24/200\n",
      "42/42 - 0s - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 25/200\n",
      "42/42 - 0s - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 26/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 27/200\n",
      "42/42 - 0s - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 28/200\n",
      "42/42 - 0s - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 29/200\n",
      "42/42 - 0s - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 30/200\n",
      "42/42 - 0s - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 31/200\n",
      "42/42 - 0s - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 32/200\n",
      "42/42 - 0s - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 33/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 34/200\n",
      "42/42 - 0s - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 35/200\n",
      "42/42 - 0s - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 36/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 37/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 38/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 39/200\n",
      "42/42 - 0s - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 40/200\n",
      "42/42 - 0s - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 41/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 42/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 43/200\n",
      "42/42 - 0s - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 44/200\n",
      "42/42 - 0s - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 45/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 46/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 47/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 48/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 49/200\n",
      "42/42 - 0s - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 50/200\n",
      "42/42 - 0s - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 51/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 52/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 53/200\n",
      "42/42 - 0s - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 54/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 55/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 56/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 57/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 58/200\n",
      "42/42 - 0s - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 59/200\n",
      "42/42 - 0s - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 60/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 61/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 62/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 63/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 64/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 65/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 66/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 67/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 68/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 69/200\n",
      "42/42 - 0s - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 70/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 71/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 72/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 73/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 74/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 75/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 76/200\n",
      "42/42 - 0s - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 77/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 78/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 79/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 80/200\n",
      "42/42 - 0s - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 81/200\n",
      "42/42 - 0s - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 82/200\n",
      "42/42 - 0s - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 83/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 84/200\n",
      "42/42 - 0s - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 85/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 86/200\n",
      "42/42 - 0s - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 87/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 88/200\n",
      "42/42 - 0s - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 89/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 90/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 91/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 92/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 93/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 94/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 95/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 96/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 97/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 98/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 99/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 100/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 102/200\n",
      "42/42 - 0s - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 103/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 104/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 105/200\n",
      "42/42 - 0s - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 106/200\n",
      "42/42 - 0s - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 107/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 108/200\n",
      "42/42 - 0s - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 109/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 110/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 111/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 112/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 114/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 115/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 116/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 117/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 118/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 119/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 120/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 121/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 122/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 123/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 124/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 125/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 126/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 127/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 128/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 129/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 130/200\n",
      "42/42 - 0s - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 131/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 132/200\n",
      "42/42 - 0s - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 133/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 134/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 135/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 136/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 137/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 138/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 140/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 141/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 142/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 143/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 144/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 145/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 146/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 147/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 148/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 149/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 150/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 151/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 152/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 153/200\n",
      "42/42 - 0s - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 154/200\n",
      "42/42 - 0s - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 155/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 156/200\n",
      "42/42 - 0s - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 157/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 158/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 159/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 160/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 161/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 162/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 163/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 164/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 165/200\n",
      "42/42 - 0s - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 166/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 167/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 168/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 169/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 170/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 171/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 172/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 173/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 174/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 175/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 176/200\n",
      "42/42 - 0s - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 177/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 178/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 179/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 180/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 181/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 182/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 183/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 184/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 185/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 186/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 187/200\n",
      "42/42 - 0s - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 188/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 189/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 190/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 191/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 192/200\n",
      "42/42 - 0s - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 193/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 194/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 195/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 196/200\n",
      "42/42 - 0s - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 197/200\n",
      "42/42 - 0s - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 198/200\n",
      "42/42 - 0s - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 199/200\n",
      "42/42 - 0s - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 200/200\n",
      "42/42 - 0s - loss: 0.0034 - val_loss: 0.0020\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train_left, X_train_right, epochs=200, batch_size=16, verbose=2, validation_data=(X_test_left,X_test_right))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder_with_label.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "# load the model from file\n",
    "encoder = load_model('encoder_with_label.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train_left)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test_left)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "# calculate classification accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
